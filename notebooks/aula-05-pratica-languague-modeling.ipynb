{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNDKc7lVAWNFbbbM+0El9BH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/gist/guardiaum/30d02ad7f806788b1c212d83057be703/aula-05-pratica-languague-modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![logo-home-copy-496x80a-red.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "DnmroWxWyxPK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vamos definir um modelo de linguagem a nível de caracteres.\n",
        "\n",
        "\n",
        "Fonte: Esse notebook é baseado na aula do [Andrej Karpathy](https://karpathy.ai/), um dos membros fundadores da OpenAI, em seu canal no [YouTube](https://www.youtube.com/watch?v=kCc8FmEb1nY)"
      ],
      "metadata": {
        "id": "bbrXPAZlN0pr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download, Carregamento e Tokenização do Corpus de Treino"
      ],
      "metadata": {
        "id": "WgxKhXWcVMJ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvit_g_pM-0b",
        "outputId": "50404306-4940-43eb-8448-a982acd340dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-02-02 23:26:53--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-02-02 23:26:54 (101 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fazendo o download e carregando o corpus que será utilizado para treino\n",
        "# É um pequeno conjunto dos escritos de shakespeare\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('input.txt', 'r', encoding='utf-8') as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "c1iUoVy7P-1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# verificando o tamanho do conjunto de dados em número de caracteres\n",
        "print(\"length of dataset in characters: \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsM7YfTTQEKz",
        "outputId": "aa3f8011-c7e7-442a-e41a-4e773100f77e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters:  1115394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Uma breve inspeção desses dados\n",
        "print(text[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0SZKgR2QEH-",
        "outputId": "25215eb8-da08-49dc-e644-9ee4c68e9bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(text)))   # o conjunto de caracteres únicos que existem no corpus\n",
        "print(\"Unique Characters: {0}\".format(''.join(chars)))\n",
        "\n",
        "vocab_size = len(chars)           # tamanho do vocabulário\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jb_LBAyvQlSN",
        "outputId": "358406c4-fd2d-47b7-c1de-ac60954a6b42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mapeando cada caractere a um índice\n",
        "c2i = { ch:i for i,ch in enumerate(chars) }     # caractere para índice\n",
        "i2c = { i:ch for i,ch in enumerate(chars) }     # indice para caractere\n",
        "\n",
        "# encoder: codifica um conjunto de caracteres de uma string e converte a uma lista de inteiros\n",
        "encode = lambda s: [c2i[c] for c in s]\n",
        "\n",
        "# decoder: decodifica uma lista de inteiros, transformando-os na string de origem\n",
        "decode = lambda l: ''.join([i2c[i] for i in l]) # decoder: take a list of integers, output a string\n",
        "\n",
        "print(encode(\"hii there\"))\n",
        "print(decode(encode(\"hii there\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2EojsXSS873",
        "outputId": "45a84d17-f4da-46ce-b415-c2bc87a245d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[46, 47, 47, 1, 58, 46, 43, 56, 43]\n",
            "hii there\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Devemos codificar todo o texto e armazená-lo em um tensor\n",
        "texto_codificado = encode(text)\n",
        "data = torch.tensor(texto_codificado, dtype=torch.long)\n",
        "\n",
        "print(data.shape, data.dtype)\n",
        "\n",
        "# Os 1000 caracteres que visualizamos anteriormente\n",
        "print(data[:1000])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1qYUhv12KD49",
        "outputId": "74f4988c-b78e-4ff7-96a6-c28fd4d8fe5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1115394]) torch.int64\n",
            "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
            "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
            "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
            "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
            "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
            "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
            "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
            "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
            "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
            "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
            "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
            "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
            "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
            "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
            "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
            "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
            "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
            "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
            "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
            "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
            "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
            "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
            "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
            "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
            "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
            "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
            "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
            "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
            "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
            "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
            "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
            "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
            "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
            "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
            "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
            "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
            "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
            "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
            "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
            "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
            "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
            "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
            "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
            "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
            "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
            "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
            "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
            "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
            "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
            "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
            "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
            "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
            "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
            "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
            "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precisamos separar o nosso conjunto de dados em conjuntos de treino e validação\n",
        "# vamos utilizar os primeiros 90% caracteres como treino e o restante será utilizado para validação\n",
        "n = int(0.9*len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]"
      ],
      "metadata": {
        "id": "LzTqTAtFOkPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"train_data.shape: {0}\".format(train_data.shape))\n",
        "print(\"val_data.shape: {0}\".format(val_data.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-9MRrEfdhqU",
        "outputId": "12b73666-a9eb-4bdc-8845-5bb4455f50e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_data.shape: torch.Size([1003854])\n",
            "val_data.shape: torch.Size([111540])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A intuição utilizada para treino do modelo de linguagem"
      ],
      "metadata": {
        "id": "QD4GyM2frOXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# também chamada de dimensão de tempo (time)\n",
        "# definirá o tamanho máximo do pedaço de texto utilizado por vez\n",
        "tamanho_max_seq = 8           \n",
        "train_data[:tamanho_max_seq]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa507sl1OkLx",
        "outputId": "9189f140-20e0-4352-947d-f65f59c02e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:tamanho_max_seq+1]   # Deslocamento +1. Target para predição"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reKg8y8bg-BG",
        "outputId": "99f79e79-7983-40d5-b3c1-cd898f6919cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo: Como é realizado o treino com um único pedaço do corpus?\n",
        "x = train_data[:tamanho_max_seq]       # [18, 47, 56, 57, 58,  1, 15, 47]\n",
        "\n",
        "# Deslocamento +1: dado um contexto qualquer (conjunto de caracteres), o modelo é treinado para aprender o caractere seguinte\n",
        "y = train_data[1:tamanho_max_seq+1]    # [47, 56, 57, 58,  1, 15, 47, 58]\n",
        "\n",
        "# treino utilizando um pedaço do corpus\n",
        "# o modelo irá aprender a prever um caractere dado um determinado contexto que pode ir de 1 até tamanho_max da sequencia\n",
        "for t in range(tamanho_max_seq):\n",
        "    context = x[:t+1]\n",
        "    target = y[t]\n",
        "    print(f\"Entrada: {context} \\t-> Target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89Mjq0h8U9SG",
        "outputId": "c49aba51-d609-4655-8bba-72b22d801466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: tensor([18]) \t-> Target: 47\n",
            "Entrada: tensor([18, 47]) \t-> Target: 56\n",
            "Entrada: tensor([18, 47, 56]) \t-> Target: 57\n",
            "Entrada: tensor([18, 47, 56, 57]) \t-> Target: 58\n",
            "Entrada: tensor([18, 47, 56, 57, 58]) \t-> Target: 1\n",
            "Entrada: tensor([18, 47, 56, 57, 58,  1]) \t-> Target: 15\n",
            "Entrada: tensor([18, 47, 56, 57, 58,  1, 15]) \t-> Target: 47\n",
            "Entrada: tensor([18, 47, 56, 57, 58,  1, 15, 47]) \t-> Target: 58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilizando o conceito de treino em \"lotes\" (batches)\n",
        "É utilizado para aumentar a velocidade de treino explorando o poder computacional presente em GPUs, possibilitando o processamento de vários pedaços de texto de forma paralela."
      ],
      "metadata": {
        "id": "waRvaiDTrprk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "# definição da dimensão de batch\n",
        "# define a quantidade de sequências que serão processadas em paralelo\n",
        "tamanho_batch = 4\n",
        "\n",
        "# define o tamanho máximo da sequência para predição\n",
        "tamanho_max_seq = 8"
      ],
      "metadata": {
        "id": "M-xUpLAQioAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ix = torch.randint(len(train_data) - 8, (4,))\n",
        "torch.stack([train_data[i:i+tamanho_max_seq] for i in ix])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPrsAdANLroL",
        "outputId": "90c03de3-f2fe-4bb2-b798-905f7211410e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[57,  1, 46, 47, 57,  1, 50, 53],\n",
              "        [ 1, 58, 46, 43, 56, 43,  1, 41],\n",
              "        [17, 26, 15, 17, 10,  0, 32, 53],\n",
              "        [57, 58,  6,  1, 61, 47, 58, 46]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split (str): 'train', 'valid'\n",
        "def get_batch(split):\n",
        "    #treino ou validação?\n",
        "    data = train_data if split == 'train' else val_data\n",
        "    \n",
        "    # seleção randômica dos índices iniciais de cada lote (tamanho_batch)\n",
        "    # len(data) - tamanho_max_seq: evita-se selecionar os últimos índices \n",
        "    # do corpus visto que não existirá índice a ser usado como target\n",
        "    ix = torch.randint(len(data) - tamanho_max_seq, (tamanho_batch,))\n",
        "    \n",
        "    # para cada índice inicial selecionado randômicamente, obter os índices \n",
        "    # seguintes da sequência de tamanho tamanho_max_seq\n",
        "    x = torch.stack([data[i:i+tamanho_max_seq] for i in ix])\n",
        "    \n",
        "    # selecionar o índice seguinte à sequência como target\n",
        "    y = torch.stack([data[i+1:i+tamanho_max_seq+1] for i in ix])\n",
        "    \n",
        "    return x, y"
      ],
      "metadata": {
        "id": "1pmnHKHCI5mN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xb, yb = get_batch('train')\n",
        "print('Shape da entrada')\n",
        "print(\"(tamanho_batch, tamanho_max_seq): {0}\".format(xb.shape))\n",
        "print(xb)\n",
        "print('\\nShape dos Targets')\n",
        "print(\"(tamanho_batch, tamanho_max_seq): {0}\".format(yb.shape))\n",
        "print(yb)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAsDF-WZI4gA",
        "outputId": "136aed03-a28f-4964-d09d-5ace88107203"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape da entrada\n",
            "(tamanho_batch, tamanho_max_seq): torch.Size([4, 8])\n",
            "tensor([[ 6,  0, 14, 43, 44, 53, 56, 43],\n",
            "        [39,  1, 42, 59, 43,  1, 39, 52],\n",
            "        [47, 41, 43,  1, 39, 52, 42,  1],\n",
            "        [53, 44,  1, 50, 43, 58,  1, 58]])\n",
            "\n",
            "Shape dos Targets\n",
            "(tamanho_batch, tamanho_max_seq): torch.Size([4, 8])\n",
            "tensor([[ 0, 14, 43, 44, 53, 56, 43,  1],\n",
            "        [ 1, 42, 59, 43,  1, 39, 52, 42],\n",
            "        [41, 43,  1, 39, 52, 42,  1, 42],\n",
            "        [44,  1, 50, 43, 58,  1, 58, 46]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for b in range(tamanho_batch): # batch dimension\n",
        "    for t in range(tamanho_max_seq): # time dimension\n",
        "        context = xb[b, :t+1]\n",
        "        target = yb[b,t]\n",
        "        print(f\"Entrada: {context.tolist()}\\t-> Target: {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7PYzuXJR5LO",
        "outputId": "a5cad3a0-def7-4e27-f7e6-04efa0b26fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrada: [6]\t-> Target: 0\n",
            "Entrada: [6, 0]\t-> Target: 14\n",
            "Entrada: [6, 0, 14]\t-> Target: 43\n",
            "Entrada: [6, 0, 14, 43]\t-> Target: 44\n",
            "Entrada: [6, 0, 14, 43, 44]\t-> Target: 53\n",
            "Entrada: [6, 0, 14, 43, 44, 53]\t-> Target: 56\n",
            "Entrada: [6, 0, 14, 43, 44, 53, 56]\t-> Target: 43\n",
            "Entrada: [6, 0, 14, 43, 44, 53, 56, 43]\t-> Target: 1\n",
            "Entrada: [39]\t-> Target: 1\n",
            "Entrada: [39, 1]\t-> Target: 42\n",
            "Entrada: [39, 1, 42]\t-> Target: 59\n",
            "Entrada: [39, 1, 42, 59]\t-> Target: 43\n",
            "Entrada: [39, 1, 42, 59, 43]\t-> Target: 1\n",
            "Entrada: [39, 1, 42, 59, 43, 1]\t-> Target: 39\n",
            "Entrada: [39, 1, 42, 59, 43, 1, 39]\t-> Target: 52\n",
            "Entrada: [39, 1, 42, 59, 43, 1, 39, 52]\t-> Target: 42\n",
            "Entrada: [47]\t-> Target: 41\n",
            "Entrada: [47, 41]\t-> Target: 43\n",
            "Entrada: [47, 41, 43]\t-> Target: 1\n",
            "Entrada: [47, 41, 43, 1]\t-> Target: 39\n",
            "Entrada: [47, 41, 43, 1, 39]\t-> Target: 52\n",
            "Entrada: [47, 41, 43, 1, 39, 52]\t-> Target: 42\n",
            "Entrada: [47, 41, 43, 1, 39, 52, 42]\t-> Target: 1\n",
            "Entrada: [47, 41, 43, 1, 39, 52, 42, 1]\t-> Target: 42\n",
            "Entrada: [53]\t-> Target: 44\n",
            "Entrada: [53, 44]\t-> Target: 1\n",
            "Entrada: [53, 44, 1]\t-> Target: 50\n",
            "Entrada: [53, 44, 1, 50]\t-> Target: 43\n",
            "Entrada: [53, 44, 1, 50, 43]\t-> Target: 58\n",
            "Entrada: [53, 44, 1, 50, 43, 58]\t-> Target: 1\n",
            "Entrada: [53, 44, 1, 50, 43, 58, 1]\t-> Target: 58\n",
            "Entrada: [53, 44, 1, 50, 43, 58, 1, 58]\t-> Target: 46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Modelo de Linguagem Baseado em Bigramas"
      ],
      "metadata": {
        "id": "ZwKD0dllU_ts"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "class BigramLanguageModel(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        # as probabilidade do próximo token\n",
        "        # dado um token de entrada as probabilidades do próximo token são armazenadas nessa lookup table\n",
        "        # cada token entregue como entrada fará a leitura da linha correspondente a ele nessa lookup table\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "\n",
        "        # os índices e targets entregues como entrada são tensores inteiros de dimensões (Batch, Time)\n",
        "        # ou seja, batch e tamanho máximo da sequencia\n",
        "        # Ao entregar os índices para a lookup table, após a leitura, serão retornados os logits para àquele índice\n",
        "        # a dimensão do tensor retornado passará a ser (Batch, Time, Channel)\n",
        "        # ou seja, batch, tamanho máximo da sequência e o tamanho do vocabulário\n",
        "        # os logits são os \"scores\" do próximo caracter na sequência\n",
        "        logits = self.token_embedding_table(idx) # (B, T, C)\n",
        "        \n",
        "        if targets is None:  # verificação para ignorar targets em tempo de geração\n",
        "            loss = None\n",
        "        else:\n",
        "            # Nós temos que reestruturar o nosso tensor devido a função cross_entropy que utilizaremos a seguir\n",
        "            # a função cross_entropy requer um tensor com dimensões (B, C, T)\n",
        "            B, T, C = logits.shape\n",
        "\n",
        "            # os logits atualmente apresentam dimensões (B, T, C) \n",
        "            # para transformar esse tensor devemos multiplicar B por T\n",
        "            # e obter um vetor de apenas duas dimensões\n",
        "            logits = logits.view(B*T, C)\n",
        "\n",
        "            # o tensor de target apresenta dimensões (B, T), assim devemos multiplicá-las a fim de obter uma única dimensão\n",
        "            targets = targets.view(B*T)\n",
        "\n",
        "            # Computa a qualidade dos logits calculados em relação aos targets esperados\n",
        "            # Quão boa está a predição dos targets considerando os logits calculados\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "    \n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # get the predictions\n",
        "            logits, loss = self(idx)\n",
        "            # focus only on the last time step\n",
        "            logits = logits[:, -1, :] # becomes (B, C)\n",
        "            # apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "            # append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "        return idx"
      ],
      "metadata": {
        "id": "xb44kSReU4Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BigramLanguageModel(vocab_size)\n",
        "logits, loss = model(xb, yb)\n",
        "print(logits.shape)\n",
        "print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYOBPYA4Sgs4",
        "outputId": "a33a6087-650d-4527-edce-57a425d1a40b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 65])\n",
            "tensor(4.8098, grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = torch.zeros((1, 1), dtype=torch.long)\n",
        "geracao = model.generate(indices, max_new_tokens=100)[0].tolist()\n",
        "\n",
        "# a geração irá retornar indices que devem ser decodificados para então conseguirmos ler os caracteres\n",
        "print(decode(geracao))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMNDDejPTkJ8",
        "outputId": "f54b9e3c-c98e-48e1-9094-3abdec79de24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "SKIcLT;AcELMoTbvZv C?nq-QE33:CJqkOKH-q;:la!oiywkHjgChzbQ?u!3bLIgwevmyFJGUGp\n",
            "wnYWmnxKWWev-tDqXErVKLgJ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Treinando o modelo Bigrama"
      ],
      "metadata": {
        "id": "XDA4MMJLXlh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)  # define um otimizador\n",
        "intervalo_avaliacao = 300\n",
        "iteracoes_maximas = 10000"
      ],
      "metadata": {
        "id": "OIL7wrPOcaqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  model.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(intervalo_avaliacao)\n",
        "    for k in range(intervalo_avaliacao):\n",
        "      X, Y = get_batch(split)\n",
        "      logits, loss = model(X, Y)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  model.train()\n",
        "  return out"
      ],
      "metadata": {
        "id": "k_MwPQ-CcZtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # aumenta o tamanho do batch\n",
        "for iter in range(iteracoes_maximas): # increase number of steps for good results... \n",
        "  # vez em quando avaliar a loss nos conjuntos de treino e validação\n",
        "  if iter % intervalo_avaliacao == 0:\n",
        "      losses = estimate_loss()\n",
        "      print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "  xb, yb = get_batch('train')   # seleciona um batch para treino do modelo\n",
        "\n",
        "  # evaluate the loss\n",
        "  logits, loss = model(xb, yb)  # passa o conjunto de dados para o modelo e recupera os logits e a loss\n",
        "  optimizer.zero_grad(set_to_none=True)  # zera os gradientes do passo anterior\n",
        "  loss.backward()  # obtém os gradientes para os parâmetros\n",
        "  optimizer.step()  # atualiza os parâmetros utilizando os gradientes obtidos anteriormente"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OO9vtdxiXlKu",
        "outputId": "cc2b7372-02f2-42c8-91ac-83f73706e1ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 2.4653, val loss 2.4754\n",
            "step 300: train loss 2.4484, val loss 2.4715\n",
            "step 600: train loss 2.4601, val loss 2.4797\n",
            "step 900: train loss 2.4803, val loss 2.4941\n",
            "step 1200: train loss 2.4911, val loss 2.4785\n",
            "step 1500: train loss 2.4662, val loss 2.4955\n",
            "step 1800: train loss 2.4442, val loss 2.4746\n",
            "step 2100: train loss 2.4528, val loss 2.4942\n",
            "step 2400: train loss 2.4564, val loss 2.4941\n",
            "step 2700: train loss 2.4769, val loss 2.5006\n",
            "step 3000: train loss 2.4573, val loss 2.4597\n",
            "step 3300: train loss 2.4453, val loss 2.4816\n",
            "step 3600: train loss 2.4420, val loss 2.4703\n",
            "step 3900: train loss 2.4843, val loss 2.4932\n",
            "step 4200: train loss 2.4515, val loss 2.4784\n",
            "step 4500: train loss 2.4703, val loss 2.4894\n",
            "step 4800: train loss 2.4582, val loss 2.4725\n",
            "step 5100: train loss 2.4803, val loss 2.4713\n",
            "step 5400: train loss 2.4463, val loss 2.4821\n",
            "step 5700: train loss 2.4674, val loss 2.4738\n",
            "step 6000: train loss 2.4586, val loss 2.4572\n",
            "step 6300: train loss 2.4534, val loss 2.4794\n",
            "step 6600: train loss 2.4461, val loss 2.4828\n",
            "step 6900: train loss 2.4545, val loss 2.4907\n",
            "step 7200: train loss 2.4677, val loss 2.4602\n",
            "step 7500: train loss 2.4565, val loss 2.4990\n",
            "step 7800: train loss 2.4496, val loss 2.4576\n",
            "step 8100: train loss 2.4577, val loss 2.4739\n",
            "step 8400: train loss 2.4646, val loss 2.5068\n",
            "step 8700: train loss 2.4657, val loss 2.4880\n",
            "step 9000: train loss 2.4662, val loss 2.4791\n",
            "step 9300: train loss 2.4683, val loss 2.4564\n",
            "step 9600: train loss 2.4608, val loss 2.4719\n",
            "step 9900: train loss 2.4531, val loss 2.4832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indices = torch.zeros((1, 1), dtype=torch.long)\n",
        "geracao = model.generate(indices, max_new_tokens=500)[0].tolist()\n",
        "\n",
        "# a geração irá retornar indices que devem ser decodificados para então conseguirmos ler os caracteres\n",
        "print(decode(geracao))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kT-FOZJnYwoU",
        "outputId": "2ba96eda-13a7-45fd-a9ee-65a83b15d1e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "osesthanha m well,\n",
            "F ticleasuolur d\n",
            "T:\n",
            "pesomo owst pugino d\n",
            "\n",
            "ARif w k ithofe th, Roue s ped tha okifok, de\n",
            "Ar.\n",
            "\n",
            "HESerel ama hatar: Byour vet hr with is aras Tht; thapu y, thind hathinthethamiouro oul! II and s l SS:\n",
            "Iffof; hat t-aroresere and; s fover;\n",
            "\n",
            "AUMENGHALA:\n",
            "A:\n",
            "This;\n",
            "I t.\n",
            "NAn thal\n",
            "Fiotha her owa\n",
            "Fouidif toury aris ion yoress ane hit in,\n",
            "O:\n",
            "LETAUns.\n",
            "Isat t ust far t?\n",
            "UCovelacef f t Bokerdace\n",
            "My MNu niris,\n",
            "G oue, hon buime.\n",
            "adive momo, warawoofe, M: atre deseeshen tar me ifukeshaceweag t qu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8M3niknWdOZ8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}